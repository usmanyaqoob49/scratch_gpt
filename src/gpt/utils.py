"""
This module has all utils like configuration of the gpt model, implementation of the GELU, implmentation of 
feed forward network module that all will be used in gpt module.
"""
import torch
import torch.nn as nn

#Settings for GPT-2 (124M) 
GPT_CONFIG_124M= {
    'vocab_size': 50257, 
    'context_length': 1024,
    'emb_dim': 768,
    'n_heads': 12,
    'n_layers': 12,
    'drop_out': 0.1, 
    'qkv_bias': False
}

#------GeLu Implementation--->This is specific implementation use in GPT-2
class GELU(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x):
        return 0.5 * x * (1 + torch.tanh(
            torch.sqrt(torch.tensor(2.0 / torch.pi)) *
            (x + 0.044715 * torch.pow(x, 3))
        ))
    
#-----Feed Forward Network 
class FeedForward(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.layers= nn.Sequential(
            nn.Linear(cfg['emb_dim'], 4* cfg['emb_dim']),
            GELU(),
            nn.Linear(4* cfg['emb_dim'], cfg['emb_dim'])
        )
    
    def forward(self, x):
        return self.layers(x)

#----- Generate text from logits that are generated by the GPT model
def generate_text(gpt_model, idx, max_new_tokens, context_size):
    for _ in max_new_tokens:
        idx_context= idx[:, -context_size:]     #only pass specific number of tokens that are allowed by context size
