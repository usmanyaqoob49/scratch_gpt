# scratch gpt
Project that has:
        - Data preparation codes that we need for using the coding the LLM like GPT-2 from scratch in src.data_preparation.
        - Scratch Codes of Scaled Self Attention, Causal Self Attention, Multihead Attention in src.attention_mechanism.
        - GPT-2 124M architecture developed from scratch using pytorch in src.gpt.
        -