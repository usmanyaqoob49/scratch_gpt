# scratch gpt
Project that has:
        - Scratch Codes of Scaled Self Attention, Causal Self Attention, Multihead Attention in src.attention_mechanism.
        - Data preparation codes that we need for using the coding the LLM like GPT-2 from scratch in src.data_preparation.
        -